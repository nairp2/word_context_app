{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3d1adfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.language import Language\n",
    "import os\n",
    "import docx2txt\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f1bbb022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tok2vec', 'tagger', 'attribute_ruler', 'lemmatizer']\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_lg',disable = ['ner', 'parser'])\n",
    "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "db2cf89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\fishrak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\fishrak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61155840",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642e39da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fcd56b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bbc_doc\\business\\001.docx\n",
      "bbc_doc\\business\\002.docx\n",
      "bbc_doc\\business\\003.docx\n",
      "bbc_doc\\business\\004.docx\n",
      "bbc_doc\\business\\005.docx\n",
      "bbc_doc\\entertainment\\001.docx\n",
      "bbc_doc\\entertainment\\002.docx\n",
      "bbc_doc\\entertainment\\003.docx\n",
      "bbc_doc\\entertainment\\004.docx\n",
      "bbc_doc\\entertainment\\005.docx\n",
      "bbc_doc\\politics\\001.docx\n",
      "bbc_doc\\politics\\002.docx\n",
      "bbc_doc\\politics\\003.docx\n",
      "bbc_doc\\politics\\004.docx\n",
      "bbc_doc\\politics\\005.docx\n",
      "bbc_doc\\sports\\001.docx\n",
      "bbc_doc\\sports\\002.docx\n",
      "bbc_doc\\sports\\003.docx\n",
      "bbc_doc\\sports\\004.docx\n",
      "bbc_doc\\sports\\005.docx\n",
      "bbc_doc\\technology\\001.docx\n",
      "bbc_doc\\technology\\002.docx\n",
      "bbc_doc\\technology\\003.docx\n",
      "bbc_doc\\technology\\004.docx\n",
      "bbc_doc\\technology\\005.docx\n"
     ]
    }
   ],
   "source": [
    "def all_file_paths(master_directory):   \n",
    "    business_txt_list = []\n",
    "    path_l = []\n",
    "    for root, dirs, files in os.walk(master_directory):\n",
    "        \n",
    "        \n",
    "\n",
    "        if files:\n",
    "            for i in files:\n",
    "                path = \"{}\\{}\".format(root,i)\n",
    "                if path == 'bbc_doc\\desktop.ini':\n",
    "                    continue\n",
    "                path_l.append(path)\n",
    "                \n",
    "    \n",
    "    return(path_l)\n",
    "\n",
    "all_path = all_file_paths('bbc_doc')\n",
    "\n",
    "for i in all_path:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59ed012d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocessor(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    text = re.sub('[\\W]+', '', text.lower())\n",
    "    return text\n",
    "\n",
    "\n",
    "def findline(word,doc_list): #Added doc_list as var\n",
    "    line_num = []\n",
    "    line_list = []\n",
    "    for i in range(len(doc_list)):\n",
    "        if word in doc_list[i]:\n",
    "            line_num.append(i+1)\n",
    "            line_list.append(doc_list[i])\n",
    "\n",
    "    return line_num, line_list\n",
    "\n",
    "\n",
    "def word_occurences(text, tokens_str, query):\n",
    "    \n",
    "    wordfreq = []\n",
    "    for w in tokens_str:\n",
    "        wordfreq.append(tokens_str.count(w))\n",
    "\n",
    "\n",
    "    for i in list(zip(tokens_str, wordfreq)):\n",
    "        if query == i[0]:\n",
    "            word_occurences = (i[0], i[1])\n",
    "            break\n",
    "\n",
    "    line = 0\n",
    "    word_not_found = []\n",
    "\n",
    "    for word in text:\n",
    "        if word == '\\n':\n",
    "            line += 1\n",
    "\n",
    "    doc_list = text.lower().splitlines()\n",
    "    doc_list = [i for i in doc_list if i]\n",
    "    \n",
    "    return doc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46639d71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "93f8f746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_word(path,query,score):\n",
    " \n",
    "#FI\n",
    "    text = docx2txt.process(path)\n",
    "    string_txt = str(text)\n",
    "\n",
    "    tokens = nlp(text)\n",
    "    lemma_list = []\n",
    "    for token in tokens:\n",
    "        if token.is_stop is False:\n",
    "            token_preprocessed = preprocessor(token.text)\n",
    "            if token_preprocessed != '':\n",
    "                 lemma_list.append(nlp(token_preprocessed))\n",
    "   \n",
    "\n",
    "    tokens_str = text.lower()\n",
    "    tokens_str = word_tokenize(tokens_str)\n",
    "    tokens_str = [i for i in tokens_str if not i in stop_words]    \n",
    "#FI    \n",
    "    \n",
    "    query = query\n",
    "    \n",
    "    l_q = len(nlp(query))\n",
    "    \n",
    "    if l_q >= 2:\n",
    "        \n",
    "        bi_g = []\n",
    "        c=0\n",
    "        while c < len(lemma_list)-1:\n",
    "\n",
    "            bi_g.append(nlp(lemma_list[c].text+\" \"+lemma_list[c+1].text))\n",
    "            c = c+1\n",
    "\n",
    "\n",
    "        lemma_list = lemma_list+bi_g\n",
    "    \n",
    "#PN \n",
    "    doc_list = word_occurences(text, lemma_list, query)\n",
    "    \n",
    "    string_list = []\n",
    "    paragraph_list = []\n",
    "    paragraph_matrix_list = []\n",
    "    \n",
    "    string_list.append(string_txt)\n",
    "    \n",
    "    string_list = string_list[0].splitlines()\n",
    "    \n",
    "    for word in string_list:\n",
    "        if word != '':\n",
    "            paragraph_list.append(word)\n",
    "    \n",
    "    #print(paragraph_list)\n",
    "#PN\n",
    "\n",
    "\n",
    "#FI & PN\n",
    "    key = nlp(query)\n",
    "    \n",
    "    sim_score = []\n",
    "    words = []\n",
    "    word_count = []\n",
    "    #paragraph_word_set = set()\n",
    "   # paragraph_sentences = []\n",
    "\n",
    "    pg_list = []\n",
    "    line_list_words = []\n",
    "\n",
    "    for i in lemma_list:\n",
    "        s = key.similarity(i)\n",
    "\n",
    "        if s > score:\n",
    "            words.append(i)\n",
    "                \n",
    "            # PN\n",
    "            \n",
    "\n",
    "            word_found_list = []\n",
    "            word_found_list.append(str(i.text))\n",
    "            word_found_lines, line_list = findline(word_found_list[0],doc_list)\n",
    "            #print(line_list)\n",
    "            l_line_list = []\n",
    "            l_line_list.append(tuple(line_list))\n",
    "            paragraph_lines = list(line_list)\n",
    "            #paragraph_lines = [ele for ele in paragraph_lines if ele != []]\n",
    "            word_count.append(len(word_found_lines))\n",
    "            \n",
    "            pg_list.append(tuple(word_found_lines))\n",
    "            line_list_words.append(tuple(line_list))\n",
    "            sim_score.append(s)\n",
    "    \n",
    "    matrix = pd.DataFrame({'Similarity Score': sim_score,'Paragraph Numbers': pg_list, 'Count': word_count, 'Paragraphs': line_list_words, 'Path': path}, index = words)\n",
    "\n",
    "    #matrix = pd.DataFrame({'Similarity Score': sim_score,'Paragraph Numbers': pg_list, 'Count': word_count}, index = words)\n",
    "    matrix = matrix.drop_duplicates()\n",
    "\n",
    "    matrix =  matrix.sort_values(by=['Similarity Score'],ascending=False)\n",
    "    #print(\"For document: {}, path: {}, keyword: {}, Similarity Score Threshold: {}\".format(os.path.basename(path),path,query,score))\n",
    "    #print(matrix)\n",
    "    return matrix\n",
    "   # print('\\n')\n",
    "\n",
    "#FI & PN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "91571f3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word_df = []\n",
    "final_df = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e315557d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check unigram,bigram, web app interface, check time complexity with 300 pages dataset, similar to google search from 1-100(access index of dataframe list: click 1 will trigger i-1 index of list)\n",
    "\n",
    "for i in all_path[:]:\n",
    "    output = sim_word(i,\"profit margin\",0.6)\n",
    "    word_df.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ab3565ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df = [df for df in word_df if not df.empty] # removing dataframes that are empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0543d3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping rows with Count having a value of 0\n",
    "for df in word_df:\n",
    "    df = df[df.Count != 0]\n",
    "    final_df.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cbe75a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Similarity Score</th>\n",
       "      <th>Paragraph Numbers</th>\n",
       "      <th>Count</th>\n",
       "      <th>Paragraphs</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(profit, margins)</th>\n",
       "      <td>0.939976</td>\n",
       "      <td>(5,)</td>\n",
       "      <td>1</td>\n",
       "      <td>(time warner's fourth quarter profits were sli...</td>\n",
       "      <td>bbc_doc\\business\\001.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(profit)</th>\n",
       "      <td>0.856083</td>\n",
       "      <td>(1, 2, 3, 4, 5)</td>\n",
       "      <td>5</td>\n",
       "      <td>(ad sales boost time warner profit, quarterly ...</td>\n",
       "      <td>bbc_doc\\business\\001.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(margins)</th>\n",
       "      <td>0.801575</td>\n",
       "      <td>(5,)</td>\n",
       "      <td>1</td>\n",
       "      <td>(time warner's fourth quarter profits were sli...</td>\n",
       "      <td>bbc_doc\\business\\001.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(quarter, profits)</th>\n",
       "      <td>0.796366</td>\n",
       "      <td>(4, 5)</td>\n",
       "      <td>2</td>\n",
       "      <td>(time warner said on friday that it now owns 8...</td>\n",
       "      <td>bbc_doc\\business\\001.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(wider, profit)</th>\n",
       "      <td>0.775118</td>\n",
       "      <td>(5,)</td>\n",
       "      <td>1</td>\n",
       "      <td>(time warner's fourth quarter profits were sli...</td>\n",
       "      <td>bbc_doc\\business\\001.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(profits)</th>\n",
       "      <td>0.772505</td>\n",
       "      <td>(2, 3, 4, 5)</td>\n",
       "      <td>4</td>\n",
       "      <td>(quarterly profits at us media giant timewarne...</td>\n",
       "      <td>bbc_doc\\business\\001.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(underlying, profit)</th>\n",
       "      <td>0.756716</td>\n",
       "      <td>(4,)</td>\n",
       "      <td>1</td>\n",
       "      <td>(time warner said on friday that it now owns 8...</td>\n",
       "      <td>bbc_doc\\business\\001.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(revenue)</th>\n",
       "      <td>0.739660</td>\n",
       "      <td>(4, 5, 6)</td>\n",
       "      <td>3</td>\n",
       "      <td>(time warner said on friday that it now owns 8...</td>\n",
       "      <td>bbc_doc\\business\\001.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(higher, revenue)</th>\n",
       "      <td>0.737573</td>\n",
       "      <td>(5,)</td>\n",
       "      <td>1</td>\n",
       "      <td>(time warner's fourth quarter profits were sli...</td>\n",
       "      <td>bbc_doc\\business\\001.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(quarterly, profits)</th>\n",
       "      <td>0.734836</td>\n",
       "      <td>(2,)</td>\n",
       "      <td>1</td>\n",
       "      <td>(quarterly profits at us media giant timewarne...</td>\n",
       "      <td>bbc_doc\\business\\001.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(profit, dip)</th>\n",
       "      <td>0.731868</td>\n",
       "      <td>(3,)</td>\n",
       "      <td>1</td>\n",
       "      <td>(the firm, which is now one of the biggest inv...</td>\n",
       "      <td>bbc_doc\\business\\001.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(earnings, growth)</th>\n",
       "      <td>0.725828</td>\n",
       "      <td>(5,)</td>\n",
       "      <td>1</td>\n",
       "      <td>(time warner's fourth quarter profits were sli...</td>\n",
       "      <td>bbc_doc\\business\\001.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(operating, earnings)</th>\n",
       "      <td>0.712284</td>\n",
       "      <td>(5,)</td>\n",
       "      <td>1</td>\n",
       "      <td>(time warner's fourth quarter profits were sli...</td>\n",
       "      <td>bbc_doc\\business\\001.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(earnings)</th>\n",
       "      <td>0.695853</td>\n",
       "      <td>(5,)</td>\n",
       "      <td>1</td>\n",
       "      <td>(time warner's fourth quarter profits were sli...</td>\n",
       "      <td>bbc_doc\\business\\001.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(profits, slump)</th>\n",
       "      <td>0.694648</td>\n",
       "      <td>(5,)</td>\n",
       "      <td>1</td>\n",
       "      <td>(time warner's fourth quarter profits were sli...</td>\n",
       "      <td>bbc_doc\\business\\001.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(saw, profits)</th>\n",
       "      <td>0.692601</td>\n",
       "      <td>(5,)</td>\n",
       "      <td>1</td>\n",
       "      <td>(time warner's fourth quarter profits were sli...</td>\n",
       "      <td>bbc_doc\\business\\001.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(quarter, sales)</th>\n",
       "      <td>0.688070</td>\n",
       "      <td>(3,)</td>\n",
       "      <td>1</td>\n",
       "      <td>(the firm, which is now one of the biggest inv...</td>\n",
       "      <td>bbc_doc\\business\\001.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(revenues)</th>\n",
       "      <td>0.687793</td>\n",
       "      <td>(4, 5)</td>\n",
       "      <td>2</td>\n",
       "      <td>(time warner said on friday that it now owns 8...</td>\n",
       "      <td>bbc_doc\\business\\001.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(advertising, revenue)</th>\n",
       "      <td>0.654288</td>\n",
       "      <td>(4, 6)</td>\n",
       "      <td>2</td>\n",
       "      <td>(time warner said on friday that it now owns 8...</td>\n",
       "      <td>bbc_doc\\business\\001.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(advertising, revenues)</th>\n",
       "      <td>0.649341</td>\n",
       "      <td>(4,)</td>\n",
       "      <td>1</td>\n",
       "      <td>(time warner said on friday that it now owns 8...</td>\n",
       "      <td>bbc_doc\\business\\001.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(revenues, grew)</th>\n",
       "      <td>0.622661</td>\n",
       "      <td>(5,)</td>\n",
       "      <td>1</td>\n",
       "      <td>(time warner's fourth quarter profits were sli...</td>\n",
       "      <td>bbc_doc\\business\\001.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(gains)</th>\n",
       "      <td>0.619050</td>\n",
       "      <td>(3,)</td>\n",
       "      <td>1</td>\n",
       "      <td>(the firm, which is now one of the biggest inv...</td>\n",
       "      <td>bbc_doc\\business\\001.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(warner, profit)</th>\n",
       "      <td>0.605188</td>\n",
       "      <td>(1,)</td>\n",
       "      <td>1</td>\n",
       "      <td>(ad sales boost time warner profit,)</td>\n",
       "      <td>bbc_doc\\business\\001.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(quarter)</th>\n",
       "      <td>0.600717</td>\n",
       "      <td>(2, 3, 4, 5)</td>\n",
       "      <td>4</td>\n",
       "      <td>(quarterly profits at us media giant timewarne...</td>\n",
       "      <td>bbc_doc\\business\\001.docx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Similarity Score Paragraph Numbers  Count  \\\n",
       "(profit, margins)                0.939976              (5,)      1   \n",
       "(profit)                         0.856083   (1, 2, 3, 4, 5)      5   \n",
       "(margins)                        0.801575              (5,)      1   \n",
       "(quarter, profits)               0.796366            (4, 5)      2   \n",
       "(wider, profit)                  0.775118              (5,)      1   \n",
       "(profits)                        0.772505      (2, 3, 4, 5)      4   \n",
       "(underlying, profit)             0.756716              (4,)      1   \n",
       "(revenue)                        0.739660         (4, 5, 6)      3   \n",
       "(higher, revenue)                0.737573              (5,)      1   \n",
       "(quarterly, profits)             0.734836              (2,)      1   \n",
       "(profit, dip)                    0.731868              (3,)      1   \n",
       "(earnings, growth)               0.725828              (5,)      1   \n",
       "(operating, earnings)            0.712284              (5,)      1   \n",
       "(earnings)                       0.695853              (5,)      1   \n",
       "(profits, slump)                 0.694648              (5,)      1   \n",
       "(saw, profits)                   0.692601              (5,)      1   \n",
       "(quarter, sales)                 0.688070              (3,)      1   \n",
       "(revenues)                       0.687793            (4, 5)      2   \n",
       "(advertising, revenue)           0.654288            (4, 6)      2   \n",
       "(advertising, revenues)          0.649341              (4,)      1   \n",
       "(revenues, grew)                 0.622661              (5,)      1   \n",
       "(gains)                          0.619050              (3,)      1   \n",
       "(warner, profit)                 0.605188              (1,)      1   \n",
       "(quarter)                        0.600717      (2, 3, 4, 5)      4   \n",
       "\n",
       "                                                                Paragraphs  \\\n",
       "(profit, margins)        (time warner's fourth quarter profits were sli...   \n",
       "(profit)                 (ad sales boost time warner profit, quarterly ...   \n",
       "(margins)                (time warner's fourth quarter profits were sli...   \n",
       "(quarter, profits)       (time warner said on friday that it now owns 8...   \n",
       "(wider, profit)          (time warner's fourth quarter profits were sli...   \n",
       "(profits)                (quarterly profits at us media giant timewarne...   \n",
       "(underlying, profit)     (time warner said on friday that it now owns 8...   \n",
       "(revenue)                (time warner said on friday that it now owns 8...   \n",
       "(higher, revenue)        (time warner's fourth quarter profits were sli...   \n",
       "(quarterly, profits)     (quarterly profits at us media giant timewarne...   \n",
       "(profit, dip)            (the firm, which is now one of the biggest inv...   \n",
       "(earnings, growth)       (time warner's fourth quarter profits were sli...   \n",
       "(operating, earnings)    (time warner's fourth quarter profits were sli...   \n",
       "(earnings)               (time warner's fourth quarter profits were sli...   \n",
       "(profits, slump)         (time warner's fourth quarter profits were sli...   \n",
       "(saw, profits)           (time warner's fourth quarter profits were sli...   \n",
       "(quarter, sales)         (the firm, which is now one of the biggest inv...   \n",
       "(revenues)               (time warner said on friday that it now owns 8...   \n",
       "(advertising, revenue)   (time warner said on friday that it now owns 8...   \n",
       "(advertising, revenues)  (time warner said on friday that it now owns 8...   \n",
       "(revenues, grew)         (time warner's fourth quarter profits were sli...   \n",
       "(gains)                  (the firm, which is now one of the biggest inv...   \n",
       "(warner, profit)                      (ad sales boost time warner profit,)   \n",
       "(quarter)                (quarterly profits at us media giant timewarne...   \n",
       "\n",
       "                                              Path  \n",
       "(profit, margins)        bbc_doc\\business\\001.docx  \n",
       "(profit)                 bbc_doc\\business\\001.docx  \n",
       "(margins)                bbc_doc\\business\\001.docx  \n",
       "(quarter, profits)       bbc_doc\\business\\001.docx  \n",
       "(wider, profit)          bbc_doc\\business\\001.docx  \n",
       "(profits)                bbc_doc\\business\\001.docx  \n",
       "(underlying, profit)     bbc_doc\\business\\001.docx  \n",
       "(revenue)                bbc_doc\\business\\001.docx  \n",
       "(higher, revenue)        bbc_doc\\business\\001.docx  \n",
       "(quarterly, profits)     bbc_doc\\business\\001.docx  \n",
       "(profit, dip)            bbc_doc\\business\\001.docx  \n",
       "(earnings, growth)       bbc_doc\\business\\001.docx  \n",
       "(operating, earnings)    bbc_doc\\business\\001.docx  \n",
       "(earnings)               bbc_doc\\business\\001.docx  \n",
       "(profits, slump)         bbc_doc\\business\\001.docx  \n",
       "(saw, profits)           bbc_doc\\business\\001.docx  \n",
       "(quarter, sales)         bbc_doc\\business\\001.docx  \n",
       "(revenues)               bbc_doc\\business\\001.docx  \n",
       "(advertising, revenue)   bbc_doc\\business\\001.docx  \n",
       "(advertising, revenues)  bbc_doc\\business\\001.docx  \n",
       "(revenues, grew)         bbc_doc\\business\\001.docx  \n",
       "(gains)                  bbc_doc\\business\\001.docx  \n",
       "(warner, profit)         bbc_doc\\business\\001.docx  \n",
       "(quarter)                bbc_doc\\business\\001.docx  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c47f08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "966f1e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['at1',\n",
       " 'at2',\n",
       " 'at3',\n",
       " 'at4',\n",
       " 'at1 at2',\n",
       " 'at2 at3',\n",
       " 'at3 at4',\n",
       " 'at1 at2 at3',\n",
       " 'at2 at3 at4',\n",
       " 'at1 at2 at3 at4']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [\"at1\",\"at2\",\"at3\",\"at4\"]\n",
    "l2 = []\n",
    "l3 = []\n",
    "l4 = []\n",
    "\n",
    "i=0\n",
    "while i < len(l)-1:\n",
    "    print(i)\n",
    "    l2.append(l[i]+\" \"+l[i+1])\n",
    "    i = i+1\n",
    "    \n",
    "i=0\n",
    "while i < len(l)-2:\n",
    "    print(i)\n",
    "    l3.append(l[i]+\" \"+l[i+1]+\" \"+l[i+2])\n",
    "    i = i+1\n",
    "\n",
    "i=0\n",
    "while i < len(l)-3:\n",
    "    print(i)\n",
    "    l4.append(l[i]+\" \"+l[i+1]+\" \"+l[i+2]+\" \"+l[i+3])\n",
    "    i = i+1\n",
    "    \n",
    "l + l2 + l3 + l4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fc6d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if word_found_lines:\n",
    "#     pass\n",
    "# else:\n",
    "#     continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f171a36d",
   "metadata": {},
   "source": [
    "### Trying with transformer models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bc6e4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sentence_transformers import SentenceTransformer, util\n",
    "# import numpy as np\n",
    "\n",
    "# model = SentenceTransformer('stsb-roberta-large')\n",
    "\n",
    "# sentence1 = \"Word\"\n",
    "# sentence2 = \"Word\"\n",
    "# # encode sentences to get their embeddings\n",
    "# embedding1 = model.encode(sentence1, convert_to_tensor=True)\n",
    "# embedding2 = model.encode(sentence2, convert_to_tensor=True)\n",
    "# # compute similarity scores of two embeddings\n",
    "# cosine_scores = util.pytorch_cos_sim(embedding1, embedding2)\n",
    "# print(\"Sentence 1:\", sentence1)\n",
    "# print(\"Sentence 2:\", sentence2)\n",
    "# print(\"Similarity score:\", cosine_scores.item())\n",
    "\n",
    "\n",
    "# key = \"learn\"\n",
    "\n",
    "# embedding1 = model.encode(key, convert_to_tensor=True)\n",
    "\n",
    "# for i in lemma_list:\n",
    "#     i = i.text\n",
    "     \n",
    "#     embedding2 = model.encode(i, convert_to_tensor=True)\n",
    "#     # compute similarity scores of two embeddings\n",
    "#     cosine_scores = util.pytorch_cos_sim(embedding1, embedding2)\n",
    "    \n",
    "#     if cosine_scores > 0.5:\n",
    "#         print(\"Key:{} \\nWord Found:{} \\nSimilarity score:{:0.2f}\".format(key,i,np.array(cosine_scores)[0][0]))\n",
    "#         print(\"----------------------------------------------------\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8b1ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sim_word(path,query,score=0.6):\n",
    " \n",
    "# #FI\n",
    "#     text = docx2txt.process(path)\n",
    "#     string_txt = str(text)\n",
    "\n",
    "\n",
    "#     tokens = nlp(text)\n",
    "#     lemma_list = []\n",
    "#     for token in tokens:\n",
    "#         if token.is_stop is False:\n",
    "#             token_preprocessed = preprocessor(token.text)\n",
    "#             if token_preprocessed != '':\n",
    "#                  lemma_list.append(nlp(token_preprocessed))\n",
    "   \n",
    "\n",
    "# #     tokens_str = text.lower()\n",
    "# #     tokens_str = word_tokenize(tokens_str)\n",
    "# #     tokens_str = [i for i in tokens_str if not i in stop_words]  \n",
    "    \n",
    "\n",
    "    \n",
    "#     l_q = len(nlp(query))\n",
    "    \n",
    "#     if l_q >= 2:\n",
    "        \n",
    "#         bi_g = []\n",
    "#         c=0\n",
    "#         while c < len(lemma_list)-1:\n",
    "\n",
    "#             bi_g.append(nlp(lemma_list[c].text+\" \"+lemma_list[c+1].text))\n",
    "#             c = c+1\n",
    "\n",
    "\n",
    "#         lemma_list = lemma_list+bi_g\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "# #PN    \n",
    "#     doc_list = word_occurences(text, lemma_list, query)\n",
    "    \n",
    "#     string_list = []\n",
    "#     paragraph_list = []\n",
    "#     paragraph_matrix_list = []\n",
    "    \n",
    "#     string_list.append(string_txt)\n",
    "    \n",
    "#     string_list = string_list[0].splitlines()\n",
    "    \n",
    "#     for word in string_list:\n",
    "#         if word != '':\n",
    "#             paragraph_list.append(word)\n",
    "\n",
    "# #PN\n",
    "\n",
    "\n",
    "# #FI & PN\n",
    "#     key = nlp(query)\n",
    "    \n",
    "#     sim_score = []\n",
    "#     words = []\n",
    "#     word_count = []\n",
    "\n",
    "#     pg_list = []\n",
    "#     line_list_words = []\n",
    "\n",
    "\n",
    "#     for i in lemma_list:\n",
    "#         s = key.similarity(i)\n",
    "\n",
    "#         if s > score:\n",
    "#             words.append(i)\n",
    "                \n",
    "#             # PN\n",
    "#             sim_score.append(s)\n",
    "            \n",
    "#             word_found_list = []\n",
    "#             word_found_list.append(str(i.text))\n",
    "#             word_found_lines,line_list = findline(word_found_list[0],doc_list)\n",
    "            \n",
    "#             if word_found_lines:\n",
    "#                 pass\n",
    "#             else:\n",
    "#                 continue\n",
    "\n",
    "#             l_line_list = []\n",
    "#             l_line_list.append(tuple(line_list))\n",
    "#             paragraph_lines = list(line_list)\n",
    "#             #paragraph_lines = [ele for ele in paragraph_lines if ele != []]\n",
    "#             word_count.append(len(word_found_lines))\n",
    "            \n",
    "#             pg_list.append(tuple(word_found_lines))\n",
    "#             words.append(i)\n",
    "#             sim_score.append(s)\n",
    "            \n",
    "\n",
    "#     matrix = pd.DataFrame({'Similarity Score': sim_score,'Paragraph Numbers': pg_list, 'Count': word_count, 'Paragraphs': line_list_words, 'Path': path}, index = words)\n",
    "\n",
    "#     #matrix = pd.DataFrame({'Similarity Score': sim_score,'Paragraph Numbers': pg_list, 'Count': word_count}, index = words)\n",
    "#     matrix = matrix.drop_duplicates()\n",
    "\n",
    "#     matrix =  matrix.sort_values(by=['Similarity Score'],ascending=False)\n",
    "#     #print(\"For document: {}, path: {}, keyword: {}, Similarity Score Threshold: {}\".format(os.path.basename(path),path,query,score))\n",
    "#     #print(matrix)\n",
    "#     return matrix\n",
    "\n",
    "# #FI & PN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b8471c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1eae41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
