{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d1adfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.language import Language\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9c6298",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for root, dirs, files in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1bbb022",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tok2vec', 'tagger', 'attribute_ruler', 'lemmatizer']\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_lg',disable = ['ner', 'parser'])\n",
    "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45878ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"\"\"Supervised learning is the machine learning task of \n",
    "         learning a function that maps an input to an output based \n",
    "         on example input-output pairs [1] It infers a function \n",
    "         from labeled training data consisting of a set of \n",
    "         training examples [2] In supervised learning, each \n",
    "         example is a pair consisting of an input object \n",
    "         (typically a vector) and a desired output value (also \n",
    "         called the supervisory signal). A supervised learning \n",
    "         algorithm analyzes the training data and produces an \n",
    "         inferred function, which can be used for mapping new \n",
    "         examples. An optimal scenario will allow for the algorithm \n",
    "         to correctly determine the class labels for unseen \n",
    "         instances. This requires the learning algorithm to  \n",
    "         generalize from the training data to unseen situations \n",
    "         in a 'reasonable' way (see inductive bias)?\n",
    "      \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1afaf0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Supervised learning is the machine learning task of \\n         learning a function that maps an input to an output based \\n         on example input-output pairs [1] It infers a function \\n         from labeled training data consisting of a set of \\n         training examples [2] In supervised learning, each \\n         example is a pair consisting of an input object \\n         (typically a vector) and a desired output value (also \\n         called the supervisory signal). A supervised learning \\n         algorithm analyzes the training data and produces an \\n         inferred function, which can be used for mapping new \\n         examples. An optimal scenario will allow for the algorithm \\n         to correctly determine the class labels for unseen \\n         instances. This requires the learning algorithm to  \\n         generalize from the training data to unseen situations \\n         in a 'reasonable' way (see inductive bias)?\\n      \""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5cdb8784",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"learning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "855603f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx2txt\n",
    "\n",
    "# read in word file\n",
    "result = docx2txt.process(\"doc_file.docx\")\n",
    "\n",
    "# Saving content inside docx file into output.txt file\n",
    "with open(\"doc_file.txt\", \"w\") as text_file:\n",
    "    print(result, file=text_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b52aad7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[supervised,\n",
       " learning,\n",
       " machine,\n",
       " learning,\n",
       " task,\n",
       " learning,\n",
       " function,\n",
       " maps,\n",
       " input,\n",
       " output,\n",
       " based,\n",
       " example,\n",
       " input,\n",
       " output,\n",
       " pairs,\n",
       " 1,\n",
       " infers,\n",
       " function,\n",
       " labeled,\n",
       " training,\n",
       " data,\n",
       " consisting,\n",
       " set,\n",
       " training,\n",
       " examples,\n",
       " 2,\n",
       " supervised,\n",
       " learning,\n",
       " example,\n",
       " pair,\n",
       " consisting,\n",
       " input,\n",
       " object,\n",
       " typically,\n",
       " vector,\n",
       " desired,\n",
       " output,\n",
       " value,\n",
       " called,\n",
       " supervisory,\n",
       " signal,\n",
       " supervised,\n",
       " learning,\n",
       " algorithm,\n",
       " analyzes,\n",
       " training,\n",
       " data,\n",
       " produces,\n",
       " inferred,\n",
       " function,\n",
       " mapping,\n",
       " new,\n",
       " examples,\n",
       " optimal,\n",
       " scenario,\n",
       " allow,\n",
       " algorithm,\n",
       " correctly,\n",
       " determine,\n",
       " class,\n",
       " labels,\n",
       " unseen,\n",
       " instances,\n",
       " requires,\n",
       " learning,\n",
       " algorithm,\n",
       " generalize,\n",
       " training,\n",
       " data,\n",
       " unseen,\n",
       " situations,\n",
       " reasonable,\n",
       " way,\n",
       " inductive,\n",
       " bias]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def preprocessor(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    text = re.sub('[\\W]+', '', text.lower())\n",
    "    return text\n",
    "\n",
    "tokens = nlp(doc)\n",
    "lemma_list = []\n",
    "for token in tokens:\n",
    "    if token.is_stop is False:\n",
    "        token_preprocessed = preprocessor(token.text)\n",
    "        if token_preprocessed != '':\n",
    "             lemma_list.append(nlp(token_preprocessed))\n",
    "lemma_list\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82f1572b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pnair\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\pnair\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9530c321",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_str = doc.lower()\n",
    "tokens_str = word_tokenize(tokens_str)\n",
    "tokens_str = [i for i in tokens_str if not i in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed1af912",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordfreq = []\n",
    "for w in tokens_str:\n",
    "    wordfreq.append(tokens_str.count(w))\n",
    "\n",
    "#print(\"List\\n\" + str(tokens_str) + \"\\n\")\n",
    "#print(\"Frequencies\\n\" + str(wordfreq) + \"\\n\")\n",
    "#print(\"Pairs\\n\" + str(list(zip(tokens_str, wordfreq))))\n",
    "\n",
    "for i in list(zip(tokens_str, wordfreq)):\n",
    "    if query == i[0]:\n",
    "        word_occurences = (i[0], i[1])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cdb5068a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of\n",
    "# lines in the file\n",
    "line = 0\n",
    "for word in doc:\n",
    "    if word == '\\n':\n",
    "        line += 1\n",
    "#print(\"Number of lines in file is: \", line)\n",
    "\n",
    "doc_list = doc.splitlines()\n",
    "\n",
    "def findline(word):\n",
    "    line_num = []\n",
    "    for i in range(len(doc_list)):\n",
    "        if word in doc_list[i]:\n",
    "            line_num.append(i+1)\n",
    "    return line_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e2f50761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key:learning \n",
      "Word Found:learning \n",
      "Similarity score:1.00\n",
      "Lines: 1, 2, 5, 8, 13\n",
      "----------------------------------------------------\n",
      "Key:learning \n",
      "Word Found:learning \n",
      "Similarity score:1.00\n",
      "Lines: 1, 2, 5, 8, 13\n",
      "----------------------------------------------------\n",
      "Key:learning \n",
      "Word Found:learning \n",
      "Similarity score:1.00\n",
      "Lines: 1, 2, 5, 8, 13\n",
      "----------------------------------------------------\n",
      "Key:learning \n",
      "Word Found:training \n",
      "Similarity score:0.63\n",
      "Lines: 4, 5, 9, 14\n",
      "----------------------------------------------------\n",
      "Key:learning \n",
      "Word Found:training \n",
      "Similarity score:0.63\n",
      "Lines: 4, 5, 9, 14\n",
      "----------------------------------------------------\n",
      "Key:learning \n",
      "Word Found:learning \n",
      "Similarity score:1.00\n",
      "Lines: 1, 2, 5, 8, 13\n",
      "----------------------------------------------------\n",
      "Key:learning \n",
      "Word Found:learning \n",
      "Similarity score:1.00\n",
      "Lines: 1, 2, 5, 8, 13\n",
      "----------------------------------------------------\n",
      "Key:learning \n",
      "Word Found:training \n",
      "Similarity score:0.63\n",
      "Lines: 4, 5, 9, 14\n",
      "----------------------------------------------------\n",
      "Key:learning \n",
      "Word Found:learning \n",
      "Similarity score:1.00\n",
      "Lines: 1, 2, 5, 8, 13\n",
      "----------------------------------------------------\n",
      "Key:learning \n",
      "Word Found:training \n",
      "Similarity score:0.63\n",
      "Lines: 4, 5, 9, 14\n",
      "----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "key = nlp(query)\n",
    "\n",
    "for i in lemma_list:\n",
    "    s = key.similarity(i)\n",
    "    \n",
    "    \n",
    "    if s > 0.5:\n",
    "        word_found_list = []\n",
    "        word_found_list.append(str(i.text))\n",
    "        word_found_lines = findline(word_found_list[0])\n",
    "            \n",
    "        print(\"Key:{} \\nWord Found:{} \\nSimilarity score:{:0.2f}\".format(key,i,s))\n",
    "        print(\"Lines:\", end =\" \")\n",
    "        print(*word_found_lines, sep = \", \")\n",
    "        print(\"----------------------------------------------------\")\n",
    "        \n",
    "#print(\"The word {} exists in the lines below:\".format(query))\n",
    "#findline(query)\n",
    "#print(\"Total Word Occurences:{}\".format(word_occurences))\n",
    "#print(\"----------------------------------------------------\")\n",
    "\n",
    "# Add line number for each word found if it exists in the doc string after creating a list of word found"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
